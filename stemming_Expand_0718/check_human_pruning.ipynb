{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experoment Notes\n",
    "\n",
    "After experimentation, I think \n",
    "stemming -> expand to form -> GPT spell check result in the most comprehensive list. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('/Users/cmu-work/Code/CASOS/Vulnerability_Dictionary/stemming_Expand_0718/accusation_0726.csv', encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>GPT</th>\n",
       "      <th>Human</th>\n",
       "      <th>Human-GPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias</td>\n",
       "      <td>bias</td>\n",
       "      <td>bias</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biases</td>\n",
       "      <td>biases</td>\n",
       "      <td>biased</td>\n",
       "      <td>biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biased</td>\n",
       "      <td>biased</td>\n",
       "      <td>blame</td>\n",
       "      <td>biasedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biassed</td>\n",
       "      <td>biased</td>\n",
       "      <td>blamed</td>\n",
       "      <td>biasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biasing</td>\n",
       "      <td>biasing</td>\n",
       "      <td>blaming</td>\n",
       "      <td>blame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>wronging</td>\n",
       "      <td>wronging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>wrongly</td>\n",
       "      <td>wrongly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>wrongness</td>\n",
       "      <td>wrongness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>wrongnesses</td>\n",
       "      <td>wrongnesses</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>wrongs</td>\n",
       "      <td>wrongs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word          GPT    Human Human-GPT\n",
       "0           bias         bias     bias      bias\n",
       "1         biases       biases   biased    biased\n",
       "2         Biased       biased    blame  biasedly\n",
       "3        biassed       biased   blamed   biasing\n",
       "4        biasing      biasing  blaming     blame\n",
       "..           ...          ...      ...       ...\n",
       "200     wronging     wronging      NaN       NaN\n",
       "201      wrongly      wrongly      NaN       NaN\n",
       "202    wrongness    wrongness      NaN       NaN\n",
       "203  wrongnesses  wrongnesses      NaN       NaN\n",
       "204       wrongs       wrongs      NaN       NaN\n",
       "\n",
       "[205 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the percentage of overlap for the two columns in df\n",
    "# return the percentage of overlap\n",
    "def compare(df, col1, col2):\n",
    "    # get the length of the df\n",
    "    length = len(df)\n",
    "    # get the number of overlap\n",
    "    overlap = len(df[df[col1] == df[col2]])\n",
    "    # get the percentage of overlap\n",
    "    percentage = overlap / length\n",
    "    return percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707317073170731"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the percentage of overlap for the two columns in df\n",
    "percentage_word_GPT = compare(df, 'word', 'GPT')\n",
    "percentage_word_GPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of overlap for\n",
    "percentage_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707317073170731"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
